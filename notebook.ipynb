{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='문서에는 Aaronson에 대한 구체적인 언급이나 그의 유죄 여부에 대한 정보가 포함되어 있지 않습니다. 따라서 Aaronson이 유죄인지에 대한 답변을 제공할 수 없습니다. 추가적인 정보가 필요합니다.' response_metadata={'token_usage': <OpenAIObject at 0x1e4a2070350> JSON: {\n",
      "  \"prompt_tokens\": 2047,\n",
      "  \"completion_tokens\": 51,\n",
      "  \"total_tokens\": 2098\n",
      "}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None} id='run-90029e35-5b63-45aa-9f21-0333cc99c5dc-0'\n",
      "content='문서에서 Winston은 테이블에 다음과 같은 메시지를 썼습니다:\\n\\n1. \"FREEDOM IS SLAVERY\"\\n2. \"TWO AND TWO MAKE FIVE\"\\n3. \"GOD IS POWER\"\\n\\n이 메시지들은 그가 자신의 생각을 기록하려고 할 때 쓴 내용입니다.' response_metadata={'token_usage': <OpenAIObject at 0x1e4a2070350> JSON: {\n",
      "  \"prompt_tokens\": 2361,\n",
      "  \"completion_tokens\": 66,\n",
      "  \"total_tokens\": 2427\n",
      "}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_5bd87c427a', 'finish_reason': 'stop', 'logprobs': None} id='run-513cb44b-edf4-4dc4-a325-d7316d731a47-0'\n",
      "content='문서에서 Julia는 Winston의 사랑하는 사람으로 언급됩니다. 그들은 함께 자유롭게 있을 때 서로에 대한 강한 감정을 가지고 있었지만, Winston은 Julia를 보호하기 위해 자신의 감정을 억누르기도 했습니다. Julia는 Winston에게 중요한 인물이며, 그와의 관계는 이야기의 중요한 요소 중 하나입니다.' response_metadata={'token_usage': <OpenAIObject at 0x1e4a21fabd0> JSON: {\n",
      "  \"prompt_tokens\": 2238,\n",
      "  \"completion_tokens\": 73,\n",
      "  \"total_tokens\": 2311\n",
      "}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f905cf32a9', 'finish_reason': 'stop', 'logprobs': None} id='run-76611c0b-9fae-4152-bf53-028b8fa7d532-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(llm=llm, max_token_limit=120, return_messages=True)\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/document.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 문서를 정확하게 분석하는 전문가 입니다. 답변은 문서에 기반하여 해주세요. 모르는 내용은 모른다고 해주세요. 한국어로 답변해주세요. {context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"history\": RunnableLambda(load_memory),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(question)\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)\n",
    "    \n",
    "question_list = [\"Aaronson 은 유죄인가요?\", \"그가 테이블에 어떤 메시지를 썼나요?\", \"Julia 는 누구인가요?\"]\n",
    "for question in question_list:\n",
    "    invoke_chain(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
